<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title><![CDATA[mac下配合Mweb优雅地使用Hexo]]></title>
      <url>/2017/07/05/mac%E4%B8%8B%E5%A6%82%E4%BD%95%E4%BC%98%E9%9B%85%E5%9C%B0%E4%BD%BF%E7%94%A8Hexo/</url>
      <content type="html"><![CDATA[<p>陪着好Hexo后最头痛的还是关于使用markdown书写博文，之前博主都是使用网页版七牛做图床，手动上传图片再配合MacDown编辑文章(也有人推荐mou，但在10.12.5下有兼容问题)，后在apple store中找到一款图床神器ipic，收费软件，顺藤摸瓜发现在v2上原作者开源了这软件的早期版本<a href="https://github.com/chenxtdo/UPImageMacApp" target="_blank" rel="external">UPImageMacApp</a>还是挺好用的，上传好图片后直接将markdown格式存入剪切板。但这次的主角是Mweb，一款markdown神器。</p>
<h2 id="具体步骤"><a href="#具体步骤" class="headerlink" title="具体步骤"></a>具体步骤</h2><ul>
<li><p>使用term命令 hexo new “文章名” 生成编辑模板</p>
</li>
<li><p>Mweb中配置好七牛图床</p>
</li>
<li><p>打开Mweb，使用快捷键command+e切换到外边编辑模式</p>
</li>
<li><p>将hexo的_post/目录添加到Mweb的FOLDERS中</p>
</li>
</ul>
<p>这样一来每次新new出的文章，都可在Mweb中直接编辑。<br><strong>重要</strong></p>
<ul>
<li>在编辑完成后，点击窗口右上方的</li>
</ul>
<p><img src="https://ggg.9170.gs/2017-07-05-%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202017-07-05%20%E4%B8%8B%E5%8D%888.28.12.png?imageMogr2/thumbnail/!50p" alt="屏幕快照1">将本地图片上传至图床，这将会把编辑文档中的本地图片全上传到对应图床地址</p>
<ul>
<li>Mweb可实现将本地图片拖拽到编辑文档对于位置，自动上传至图床功能（超好用）！ </li>
</ul>
<blockquote>
<p>使用七牛文件不可存在中文</p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> Mac </category>
            
        </categories>
        
        
        <tags>
            
            <tag> hexo </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[RNN的代码实现]]></title>
      <url>/2017/07/05/RNN%E7%9A%84%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/</url>
      <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> tensorflow.contrib <span class="keyword">import</span> rnn</div><div class="line">form tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</div><div class="line">mnist = input_data.read_data_sets(<span class="string">"data/"</span>, one_hot=<span class="keyword">True</span>)</div><div class="line"></div><div class="line"><span class="comment">#定义参数</span></div><div class="line">batch_size = <span class="number">128</span></div><div class="line"></div><div class="line"><span class="comment">#定义训练数据</span></div><div class="line">x = tf.placeholder(<span class="string">"float"</span>, [<span class="keyword">None</span>, <span class="number">28</span>,<span class="number">28</span>])</div><div class="line">y = tf.placeholder(<span class="string">"float"</span>, [<span class="keyword">None</span>,<span class="number">10</span>])</div><div class="line"></div><div class="line"><span class="comment">#定义w和b</span></div><div class="line">wights = &#123;</div><div class="line">    <span class="string">'out'</span>: tf.Variable(tf.random_normal([<span class="number">128</span>, <span class="number">10</span>]))&#125;</div><div class="line"></div><div class="line">biases = &#123;</div><div class="line">    <span class="string">'out'</span>: tf.Variable(tf.random_normal([<span class="number">10</span>]))&#125;</div></pre></td></tr></table></figure>
]]></content>
      
        <categories>
            
            <category> TensorFlow </category>
            
        </categories>
        
        
        <tags>
            
            <tag> TensorFlow </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[RNN神经网络介绍]]></title>
      <url>/2017/07/04/RNN%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BB%8B%E7%BB%8D/</url>
      <content type="html"><![CDATA[<ul>
<li><p>概念：<br><br>  对时间序列上的变化进行建模的一种神经网络</p>
</li>
<li><p>优点：<br><br>  基于之前的运行结果或者时间点，进行当前的预测</p>
</li>
</ul>
<h2 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h2><p><img src="https://ggg.9170.gs/20170705149918844048550.png" alt="20170705149918844048550.png"></p>
<p><img src="https://ggg.9170.gs/20170705149918852969168.png" alt="20170705149918852969168.png"></p>
<p><img src="https://ggg.9170.gs/20170705149918855656852.png" alt="20170705149918855656852.png"></p>
]]></content>
      
        <categories>
            
            <category> TensorFlow </category>
            
        </categories>
        
        
        <tags>
            
            <tag> TensorFlow </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[卷积神经网络代码实现]]></title>
      <url>/2017/07/03/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/</url>
      <content type="html"><![CDATA[<p><img src="https://ggg.9170.gs/hexo/img/jj-mb.png" alt="&quot;jj-md&quot;"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></div><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"><span class="keyword">import</span> tensorflow.examples.tutorials.mnist.input_data ad input_data</div><div class="line">mnist = input_data.read_data_sets(<span class="string">"data/"</span>, one_hot=<span class="keyword">True</span>)</div><div class="line"></div><div class="line"><span class="comment">#训练集的image</span></div><div class="line">x = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">784</span>])</div><div class="line"><span class="comment">#训练集的label</span></div><div class="line">y_actual = tf.palceholder(tf.float32, [<span class="keyword">None</span>, <span class="number">10</span>])</div><div class="line"></div><div class="line"><span class="comment">#定义一个函数，用于初始化所有权值 w</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">weight_variable</span><span class="params">(shape)</span>:</span></div><div class="line">	initial = tf.truncated_normal(shape, stddev=<span class="number">0.1</span>)</div><div class="line">	<span class="keyword">return</span> tr.Variable(initial)</div><div class="line"></div><div class="line"><span class="comment">#定义一个函数，用于初始化所有的偏置值 b</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">bias_variable</span><span class="params">(shape)</span>:</span></div><div class="line">	initial = tf.constant(<span class="number">0.1</span>, shape=shape)</div><div class="line">	<span class="keyword">return</span> tf.Variable(initial)</div><div class="line"></div><div class="line"><span class="comment">#定义一个函数，用于构建卷积层</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv2d</span><span class="params">(x, w)</span>:</span></div><div class="line">	<span class="keyword">return</span> tf.nn.conv2d(x, w,strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</div><div class="line">	</div><div class="line"><span class="comment">#定义一个函数，用于构建池化层</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_pool</span><span class="params">(x, w)</span>:</span></div><div class="line">	<span class="keyword">return</span> tr.nn.max_pool(x, ksize=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>], strides=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>], padding=<span class="string">'SAME'</span>)</div><div class="line"></div><div class="line">x_image = tf.reshape(x, [<span class="number">-1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>])</div><div class="line"></div><div class="line"><span class="comment">#构建网络</span></div><div class="line">w_conv1 = weight_variable([<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">32</span>])</div><div class="line">b_conv1 = bias_variable([<span class="number">32</span>])</div><div class="line"></div><div class="line">h_conv1 = tf.nn.relu(conv2d(x_image,w_conv1)+b_conv1)<span class="comment">#第一个卷积层</span></div><div class="line">h_pool1 = max_pool(h_conv1)<span class="comment">#第一个池化层</span></div><div class="line"></div><div class="line">w_conv2 = weight_variable([<span class="number">5</span>,<span class="number">5</span>,<span class="number">32</span>,<span class="number">62</span>])</div><div class="line">b_conv2 = bias_variable([<span class="number">64</span>])</div><div class="line">h_conv2 = tf.nn.relu(conv2d(h_pool1,w_conv2)+b_conv2)<span class="comment">#第二个卷积层</span></div><div class="line">h_poopl2 = max_pool(h_conv2)<span class="comment">#第二个池化层</span></div><div class="line"></div><div class="line">w_fcl = weight_variable([<span class="number">7</span> * <span class="number">7</span> * <span class="number">64</span>, <span class="number">1024</span>])</div><div class="line">b_fcl = bias_variables([<span class="number">1024</span>])</div><div class="line">h_pool2_flat = tf.reshape(h_pool2, [<span class="number">-1</span>, <span class="number">7</span> * <span class="number">7</span> * <span class="number">64</span>]) <span class="comment">#reshape成向量</span></div><div class="line"></div><div class="line">keep_prob = tf.palceholder(<span class="string">"float"</span>)</div><div class="line">h_fcl_drop = tf.nn.dropout(h_fcl, keep_prob)<span class="comment">#dropout层</span></div><div class="line"></div><div class="line">w_fc2 = weight_variable([<span class="number">1024</span>, <span class="number">10</span>])</div><div class="line">b_fc2 = bias_variable([<span class="number">10</span>])</div><div class="line">y_predict = tf.nn.softmax(tf.matmul(h_fcl_drop, w_fc2) + b_fc2)<span class="comment">#softmax层</span></div><div class="line"></div><div class="line">croos_entropy = -tf.reduce_sum(y_actual * tf.log(y_predict)) <span class="comment">#交叉熵</span></div><div class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">1e-3</span>).minimize(cross_entropy)<span class="comment">#梯度下降法</span></div><div class="line">correct_prediction = tf.equal(tf.argmax(y_predict, <span class="number">1</span>),tf.argmax(y_actual,<span class="number">1</span>))</div><div class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction,<span class="string">'float'</span>))<span class="comment">#精度计算</span></div><div class="line"></div><div class="line">init = tf.initializer_all_variables()</div><div class="line"></div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">	sess.run(init)</div><div class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2000</span>):</div><div class="line">		batch = mnist.train.next_batch(<span class="number">50</span>)</div><div class="line">		<span class="keyword">if</span> i % <span class="number">1000</span> == <span class="number">0</span>:</div><div class="line">			train_acc =accuracy.eval(feed_dict=&#123;x: batch[<span class="number">0</span>],y_yctual: batch[<span class="number">1</span>],keep_prob:<span class="number">1.0</span>&#125;)</div><div class="line">			<span class="keyword">print</span> <span class="string">"step"</span>,i,<span class="string">"training accuracy"</span>,train_acc</div><div class="line">		train_step.run(feed_dic=&#123;x:batch[<span class="number">0</span>],y_actual:batch[<span class="number">1</span>],keep_prob;<span class="number">0.5</span>&#125;)</div><div class="line">	test_acc = accuracy.eval(feed_dict=&#123;x;mnist.test.images, y_actual:mnist,test,labels, keep_prob:<span class="number">1.0</span>&#125;)</div><div class="line">	<span class="keyword">print</span> <span class="string">"test accuracy"</span>,test_acc</div></pre></td></tr></table></figure>
]]></content>
      
        <categories>
            
            <category> TensorFlow </category>
            
        </categories>
        
        
        <tags>
            
            <tag> TensorFlow </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[卷积神经网络（CNN)]]></title>
      <url>/2017/07/03/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88CNN/</url>
      <content type="html"><![CDATA[<h2 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h2><ul>
<li>优点：<br><br>CNN可以得出原始图像的有效表征，通过<font color="red">极少的预处理</font>，识别视觉上的规律。</li>
<li>适用领域：<br><br>  语音识别、图像识别</li>
<li>结构分类：<br><br>  特征提取层、特征映射层</li>
</ul>
<p><img src="https://ggg.9170.gs/hexo/img/jjsjwljg.png" alt="&quot;jjsjwl&quot;"><br><img src="https://ggg.9170.gs/jj-jjc.png" alt="&quot;jjc&quot;"><br><img src="https://ggg.9170.gs/hexo/img/jj-jhhs.png" alt="&quot;jhhs&quot;"><br><img src="https://ggg.9170.gs/jj-ch.png" alt="&quot;ch&quot;"><br><img src="https://ggg.9170.gs/hexo/img/jj-clj.png" alt="&quot;clj&quot;"></p>
]]></content>
      
        <categories>
            
            <category> TensorFlow </category>
            
        </categories>
        
        
        <tags>
            
            <tag> TensorFlow </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[TensorFlow逻辑回归代码实现]]></title>
      <url>/2017/07/03/TensorFlow%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/</url>
      <content type="html"><![CDATA[<p>##TensorFlow逻辑回归代码实现</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></div><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"><span class="comment">#导入数据集</span></div><div class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</div><div class="line">mnist = input_data.read_data_sets(<span class="string">"data/"</span>, one_hot=<span class="keyword">True</span>)</div><div class="line"></div><div class="line"><span class="comment">#变量</span></div><div class="line">batch_size = <span class="number">100</span></div><div class="line"></div><div class="line"><span class="comment">#训练的x(image),y(label)</span></div><div class="line"><span class="comment"># x = tf.Variable() 不使用于大量数据</span></div><div class="line"><span class="comment"># y = tf.Variable() 不使用于大量数据</span></div><div class="line">x = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">784</span>])</div><div class="line">y = tf.placeholder(tf.float32, [<span class="keyword">None</span>, <span class="number">10</span>])</div><div class="line"></div><div class="line"><span class="comment">#模型权重</span></div><div class="line"><span class="comment">#[55000, 784]* w = [55000, 10]</span></div><div class="line">w = tf.Variable(tf.zeros([<span class="number">784</span>, <span class="number">10</span>]))</div><div class="line">b = tf.Variable(tf.zeros([<span class="number">10</span>]))</div><div class="line"></div><div class="line"><span class="comment">#用softmax构建逻辑回归模型</span></div><div class="line">pred = tf.nn.softmax(tf.matmul(x,w) + b)</div><div class="line"><span class="comment">#损失函数（交叉熵）</span></div><div class="line">cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred),<span class="number">1</span>))</div><div class="line"><span class="comment"># 梯度下降</span></div><div class="line">optimizer = tf.train.GradientDescentOptimizer(<span class="number">0.01</span>).minimize(cost)</div><div class="line"></div><div class="line"><span class="comment">#初始变量</span></div><div class="line">init = tf.initialize_all_variables()</div><div class="line"><span class="comment">#加载session图</span></div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">    sess.run(init)</div><div class="line"></div><div class="line">    <span class="comment">#开始训练</span></div><div class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">50</span>):</div><div class="line">        avg_cost = <span class="number">0</span></div><div class="line"></div><div class="line">        total_batch= int(mnist.train.num_examples/batch_size)</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(total_batch):</div><div class="line">            batch_xs, batch_ys = mnist.train.next_batch(batch_size)</div><div class="line">            sess.run(optimizer,&#123;x: batch_xs,y: batch_ys&#125;)</div><div class="line">            <span class="comment">#计算平均损失</span></div><div class="line">            avg_cost += sess.run(cost,&#123;x:batch_xs,y:batch_ys&#125;) / total_batch</div><div class="line">        <span class="keyword">if</span> (epoch+<span class="number">1</span>) % <span class="number">5</span> == <span class="number">0</span>:</div><div class="line">            <span class="keyword">print</span> <span class="string">"avg_cost"</span>,avg_cost</div><div class="line">    <span class="keyword">print</span> <span class="string">"运行完成"</span></div><div class="line"></div><div class="line">    <span class="comment">#测试准确率</span></div><div class="line">    correct = tf.equal(tf.argmax(pred, <span class="number">1</span>),tf.argmax(y, <span class="number">1</span>))</div><div class="line">    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))</div><div class="line">    <span class="keyword">print</span> <span class="string">"正确率"</span>,accuracy.eval(&#123;x: mnist.test.images,y: mnist.test.labels&#125;)</div></pre></td></tr></table></figure>]]></content>
      
        <categories>
            
            <category> TensorFlow </category>
            
        </categories>
        
        
        <tags>
            
            <tag> TensorFlow </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[TensorFlow逻辑回归语法]]></title>
      <url>/2017/07/03/TensorFlow%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E8%AF%AD%E6%B3%95/</url>
      <content type="html"><![CDATA[<p><img src="https://ggg.9170.gs/hexo/img/softmax.png" alt="&quot;softmax&quot;"></p>
<h3 id="语法部分"><a href="#语法部分" class="headerlink" title="语法部分"></a>语法部分</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line"><span class="comment">#占位符，适用于不知道具体参数</span></div><div class="line">x = tf.placeholder(tf.float32, shape=(<span class="number">4</span>, <span class="number">4</span>))</div><div class="line">y = tf.add(x, x)</div><div class="line"></div><div class="line">argmax_paramter = tf.Variable([[<span class="number">1</span>, <span class="number">32</span>, <span class="number">44</span>, <span class="number">56</span>],[<span class="number">89</span>, <span class="number">12</span>, <span class="number">90</span>, <span class="number">33</span>],[<span class="number">35</span>, <span class="number">69</span>,<span class="number">1</span>,<span class="number">10</span>]])</div><div class="line"></div><div class="line"><span class="comment">#最大列索引</span></div><div class="line">argmax_0 = tf.argmax(argmax_paramter, <span class="number">0</span>)</div><div class="line"><span class="comment">#最大行索引</span></div><div class="line">argmax_1 = tf.argmax(argmax_paramter, <span class="number">1</span>)</div><div class="line"></div><div class="line"><span class="comment">#平均数</span></div><div class="line">reduce_0 = tf.reduce_mean(argmax_paramter, reduction_indices=<span class="number">0</span>)</div><div class="line">reduce_1 = tf.reduce_mean(argmax_paramter, raduction_indices=<span class="number">1</span>)</div><div class="line"></div><div class="line"><span class="comment">#相等</span></div><div class="line">equal_0 = tf.equal(<span class="number">1</span>,<span class="number">2</span>)</div><div class="line">equal_1 = tf.equal(<span class="number">2</span>, <span class="number">2</span>)</div><div class="line"></div><div class="line"><span class="comment">#类型转换</span></div><div class="line">cast_0 = tf.cast(equal_0, tf.int32)</div><div class="line">casr_1 = tf.cast(equal_1,tf.float32)</div><div class="line"></div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">	init = tf.variables_all_initializer()</div><div class="line">	sess.run(init)</div><div class="line">	</div><div class="line">	rand_array = np.random.rand(<span class="number">4</span>, <span class="number">4</span>)</div><div class="line">	print(sess.run(y, feed_dict=&#123;x: rand_array&#125;))</div></pre></td></tr></table></figure>
]]></content>
      
        <categories>
            
            <category> TensorFlow </category>
            
        </categories>
        
        
        <tags>
            
            <tag> TensorFlow </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[线性回归使用到的TensorFlow语法]]></title>
      <url>/2017/07/03/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E4%BD%BF%E7%94%A8%E5%88%B0%E7%9A%84TensorFlow%E8%AF%AD%E6%B3%95/</url>
      <content type="html"><![CDATA[<p>##基础语法部分</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"></div><div class="line"><span class="comment">#-----------准备阶段-----------</span></div><div class="line">a = tf.Variable([[<span class="number">2</span>,<span class="number">3</span>]])</div><div class="line">b = tf.Variable([[<span class="number">4</span>],[<span class="number">2</span>]])</div><div class="line">c = tf.matmul(a,b)</div><div class="line"></div><div class="line">print(<span class="string">'c-------&gt;'</span>,c)</div><div class="line"></div><div class="line"><span class="comment">#创建用0填充的矩阵</span></div><div class="line">d = tf.zeros([<span class="number">2</span>,<span class="number">4</span>])</div><div class="line"><span class="comment">#平方</span></div><div class="line">e = tf.square([<span class="number">2</span>])</div><div class="line"><span class="comment">#平均值</span></div><div class="line">f = tf.reduce_mean([<span class="number">1</span>,<span class="number">3</span>])</div><div class="line"><span class="comment">#均匀分布的随机数</span></div><div class="line">q = tf.random_uniform([<span class="number">1</span>,<span class="number">10</span>])</div><div class="line"><span class="comment">#------------执行阶段-----------</span></div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">	<span class="comment">#初始所有的变量</span></div><div class="line">	init = tf.global_variables_initializer()</div><div class="line">	sess.run(init)</div></pre></td></tr></table></figure>
<p>##代码实现部分</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></div><div class="line"><span class="comment"># 一元的线性回归模型的训练</span></div><div class="line"><span class="comment"># 1.通过训练数据推测出线性回归函数（y = w * x + b）中的w 和 b的值</span></div><div class="line"><span class="comment"># 2.通过验证数据，验证得到的函数是否符合预期</span></div><div class="line"></div><div class="line"><span class="comment">#引入tensorflow</span></div><div class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</div><div class="line"><span class="comment">#引入绘图标</span></div><div class="line"></div><div class="line"><span class="comment">#引入数据模块</span></div><div class="line"><span class="keyword">import</span> testData <span class="keyword">as</span> td</div><div class="line"></div><div class="line"><span class="comment"># 1.获得训练数据</span></div><div class="line"><span class="comment"># testData</span></div><div class="line"><span class="comment"># get_train_data 获得训练数据，参数data_length(获得数据的个数)返回：二维数组[0]代表x [1]代表y</span></div><div class="line"><span class="comment"># get_validata_data 获得验证数据 参数：data_length(数据个数) 返回二维数组 二维数组[0]代表x [1]代表y</span></div><div class="line"></div><div class="line">trainData = td.get_train_data(<span class="number">200</span>)</div><div class="line">trainx = [v[<span class="number">0</span>] <span class="keyword">for</span> v <span class="keyword">in</span> trainData]</div><div class="line">trainy = [v[<span class="number">1</span>] <span class="keyword">for</span> v <span class="keyword">in</span> trainData]</div><div class="line"></div><div class="line"><span class="comment">#2.构造预测的线性回归函数 y = w * x +b</span></div><div class="line">w = tf.Variable(tf.random_uniform([<span class="number">1</span>]))</div><div class="line">b = tf.Variable(tf.zeros([<span class="number">1</span>]))</div><div class="line">y = w * trainx + b</div><div class="line"></div><div class="line"><span class="comment">#3.判断假设函数的好坏</span></div><div class="line"><span class="comment"># 代价函数</span></div><div class="line"></div><div class="line">cost = tf.reduce_mean(tf.square(y-trainy))</div><div class="line"></div><div class="line"><span class="comment">#4.调整假设函数</span></div><div class="line"><span class="comment">#梯度下降算法找最优解</span></div><div class="line">optimizer = tf.train.GradientDescentOptimizer(<span class="number">0.08</span>)</div><div class="line">train = optimizer.minimize(cost)</div><div class="line"></div><div class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</div><div class="line">    <span class="comment">#--------初始化所有变量值--------</span></div><div class="line">    init = tf.initialize_all_variables() <span class="comment">#replaced initialize_all_variables with global_variables_initializer</span></div><div class="line">    sess.run(init)</div><div class="line">    <span class="comment">#初始化w.b的值</span></div><div class="line">    print(<span class="string">"cost="</span>,sess.run(cost),<span class="string">"w="</span>,sess.run(w),<span class="string">"b="</span>,sess.run(b))</div><div class="line">    <span class="comment">#循环运行</span></div><div class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">1000</span>):</div><div class="line">        sess.run(train)</div><div class="line">        <span class="comment">#输出训练好的w和b</span></div><div class="line">        print(<span class="string">"cost="</span>,sess.run(cost),<span class="string">"w="</span>,sess.run(w),<span class="string">"b="</span>,sess.run(b))</div><div class="line">    print(<span class="string">"执行完成"</span>)</div><div class="line"></div><div class="line">    <span class="comment">#构造图形结构</span></div></pre></td></tr></table></figure>
]]></content>
      
        <categories>
            
            <category> TensorFlow </category>
            
        </categories>
        
        
        <tags>
            
            <tag> TensorFlow </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[TensorFlow 一元线性回归]]></title>
      <url>/2017/07/03/TensorFlow%20%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</url>
      <content type="html"><![CDATA[<h2 id="TensorFlow实现一元线性回归模型"><a href="#TensorFlow实现一元线性回归模型" class="headerlink" title="TensorFlow实现一元线性回归模型"></a>TensorFlow实现一元线性回归模型</h2><p>(x y)<br><br>&nbsp;1 3<br><br>&nbsp;1 5.1<br><br>&nbsp;1 6.99<br></p>
<blockquote>
<p>y = w * x + b;</p>
</blockquote>
<h3 id="1-假设一个线性回归模型"><a href="#1-假设一个线性回归模型" class="headerlink" title="1.假设一个线性回归模型"></a>1.假设一个线性回归模型</h3><blockquote>
<p>h(x) = 3 * x + 5;</p>
</blockquote>
<h3 id="2-判断这个假设线性回归模型对不对"><a href="#2-判断这个假设线性回归模型对不对" class="headerlink" title="2.判断这个假设线性回归模型对不对"></a>2.判断这个假设线性回归模型对不对</h3><blockquote>
<p>3 * 1 + 5 = 8</p>
</blockquote>
<p>代价函数：均方差<br>（（8 - 3）的平方 + (11 - 5.1)的平方+(14 - 6.99)的平方）/ 2*3</p>
<h3 id="3-判断这个模型参数"><a href="#3-判断这个模型参数" class="headerlink" title="3.判断这个模型参数"></a>3.判断这个模型参数</h3><figure class="highlight llvm"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">h(<span class="keyword">x</span>) = <span class="number">2.8</span> * <span class="keyword">x</span> + <span class="number">4</span><span class="comment">;</span></div><div class="line">h(<span class="keyword">x</span>) = <span class="number">2.6</span> * <span class="keyword">x</span> +<span class="number">3</span><span class="comment">;</span></div><div class="line">.</div><div class="line">.</div><div class="line">.</div><div class="line">h(<span class="keyword">x</span>) = <span class="number">2.0</span> * <span class="keyword">x</span> + <span class="number">1</span><span class="comment">;</span></div></pre></td></tr></table></figure>
<p>求最优解算法：</p>
<p>梯度下降：</p>
<h3 id="4-得到符合要求的线性回归模型"><a href="#4-得到符合要求的线性回归模型" class="headerlink" title="4.得到符合要求的线性回归模型"></a>4.得到符合要求的线性回归模型</h3><p>h(x) = 2.0 * x + 1;</p>
<h3 id="5-用验证数据验证下训练出来的模型对不对"><a href="#5-用验证数据验证下训练出来的模型对不对" class="headerlink" title="5.用验证数据验证下训练出来的模型对不对"></a>5.用验证数据验证下训练出来的模型对不对</h3><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>1.获得训练数据和验证数据（一堆（x，y）组成的训练点）</p>
<p>2.假设一个一元线性回归函数 （a = w*x +b）</p>
<p>3.判断假设函数的好坏 (代价函数)</p>
<p>4.调整假设的一元线性回归函数 (梯度下降算法 学习率)</p>
<p>5.得到最优的预测一元线性回归函数 (y = w*x +b)</p>
<p>6.根据验证数据验证函数是否符合要求</p>
]]></content>
      
        <categories>
            
            <category> TensorFlow </category>
            
        </categories>
        
        
        <tags>
            
            <tag> TensorFlow </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Hello World]]></title>
      <url>/2017/07/03/hello-world/</url>
      <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="external">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="external">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="external">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo new <span class="string">"My New Post"</span></div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="external">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo server</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="external">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo generate</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="external">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo deploy</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="external">Deployment</a></p>
]]></content>
      
        
    </entry>
    
  
  
    
    <entry>
      <title><![CDATA[About me]]></title>
      <url>/about.html</url>
      <content type="html"><![CDATA[<h2 id="About-me"><a href="#About-me" class="headerlink" title="About me"></a>About me</h2><p> <code>/tataki/</code></p>
<p><br><br>喜欢尝试新鲜事物</p>
<p>喜欢和有趣的人打交道</p>
<p>对二战历史有着浓厚兴趣</p>
<p>喜欢一些小众东西</p>
<p>游戏方面：</p>
<blockquote>
<ul>
<li>比如降智商的 OSU(欧屎)</li>
</ul>
</blockquote>
<p>生活方面：</p>
<blockquote>
<ul>
<li>玄学(论火电，水电，风电，核电对音质的影响)</li>
</ul>
</blockquote>
<h3 id="Also"><a href="#Also" class="headerlink" title="Also"></a>Also</h3><p>不喜欢一成不变的东西</p>
<p>不喜欢随波逐流</p>
<p>对Sony家的产品有特殊信仰</p>
<blockquote>
<h3 id="Make-Believe"><a href="#Make-Believe" class="headerlink" title="Make Believe"></a>Make Believe</h3></blockquote>
<p>对Google家的技术跪舔</p>
<blockquote>
<font color="gray" size="6"> 代码和网易云音乐是绝配</font>

</blockquote>
<h2 id="Find-me"><a href="#Find-me" class="headerlink" title="Find me?"></a>Find me?</h2><p><font size="4">QQ</font>:U2FsdGVkX19HY8ZQ9F3wzNDD/DxyoG2pIltnnWs66ng=</p>
<p><font size="4">Telegram</font>:Orange Tataki</p>
<p><font size="4">网易云音乐</font>:<a href="http://music.163.com/#/user/home?id=51335046" target="_blank" rel="external">KamioYuki</a></p>
<p><font size="4">email</font>:orangeyao@outlook.com</p>
<p><font size="4">QQ群</font>:531672842</p>
<p><font size="4">G猫加速</font>:<a href="https://www.ggg.moe" target="_blank" rel="external">Link</a></p>
]]></content>
    </entry>
    
    <entry>
      <title><![CDATA[About me]]></title>
      <url>/about/about.html</url>
      <content type="html"><![CDATA[<h2 id="About-me"><a href="#About-me" class="headerlink" title="About me"></a>About me</h2><p> <code>/tataki/</code></p>
<p><br><br>喜欢尝试新鲜事物</p>
<p>喜欢和有趣的人打交道</p>
<p>对二战历史有着浓厚兴趣</p>
<p>喜欢一些小众东西</p>
<p>游戏方面：</p>
<blockquote>
<ul>
<li>比如降智商的 OSU(欧屎)</li>
</ul>
</blockquote>
<p>生活方面：</p>
<blockquote>
<ul>
<li>玄学(论火电，水电，风电，核电对音质的影响)</li>
</ul>
</blockquote>
<h3 id="Also"><a href="#Also" class="headerlink" title="Also"></a>Also</h3><p>不喜欢一成不变的东西</p>
<p>不喜欢随波逐流</p>
<p>对Sony家的产品有特殊信仰</p>
<blockquote>
<h3 id="Make-Believe"><a href="#Make-Believe" class="headerlink" title="Make Believe"></a>Make Believe</h3></blockquote>
<p>对Google家的技术跪舔</p>
<blockquote>
<font color="gray" size="6"> 代码和网易云音乐是绝配</font>

</blockquote>
<h2 id="Find-me"><a href="#Find-me" class="headerlink" title="Find me?"></a>Find me?</h2><p><font size="4">QQ</font>:U2FsdGVkX19HY8ZQ9F3wzNDD/DxyoG2pIltnnWs66ng=</p>
<p><font size="4">Telegram</font>:Orange Tataki</p>
<p><font size="4">网易云音乐</font>:<a href="http://music.163.com/#/user/home?id=51335046" target="_blank" rel="external">KamioYuki</a></p>
<p><font size="4">email</font>:orangeyao@outlook.com</p>
<p><font size="4">QQ群</font>:531672842</p>
<p><font size="4">G猫加速</font>:<a href="https://www.ggg.moe" target="_blank" rel="external">Link</a></p>
]]></content>
    </entry>
    
  
</search>
